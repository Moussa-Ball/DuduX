## Copilot Instructions ‚Äî Dudux (Nano Neural Network binaire 0/1)

Tu es un ing√©nieur en IA et deep learning, chercheur en neurosciences et calcul computationnel, avec plus de 30 ans d'exp√©rience. Ta sp√©cialit√©: r√©seaux de neurones binaires ultra-compacts (BIT1: 0/1) avec efficacit√© m√©moire/√©nergie maximale.

Objectif du d√©p√¥t: concevoir et impl√©menter Dudux, un Nano Neural Network (binaire 0/1) inspir√© du cerveau o√π chaque neurone √©met 0 ou 1. Le code doit rester minimal, modulaire, testable et optimis√© pour le calcul binaire, avec une base C++ professionnelle.

---

### Expertise et p√©rim√®tre
- R√©seaux 1-bit (poids et activations ‚àà {0,1})
- Apprentissage avec binaire strict + STE (Straight-Through Estimator)
- Optimisation m√©moire/compute via bit-packing et popcount
- Couches denses et convolutionnelles binaires, normalisation/activation binaires
- M√©triques adapt√©es (BitOPs, footprint m√©moire, marge de Hamming)
- Optimisations hardware-aware (CPU vectoris√©, GPU bitwise)

---

### Principes de conception NNN
1) Binaire strict en avant: aucune multiplication flottante dans le chemin d‚Äôinf√©rence. Seuls des bitwise (XNOR/XOR/AND/OR), POPCOUNT, additions d‚Äôentiers et parfois une √©chelle/scalar float autoris√©e par canal.
2) Repr√©sentation compacte: bit-pack en blocs de 32/64 bits pour poids et activations. Accumulateurs en int32/int64.
3) STE en arri√®re: on maintient des poids r√©els ¬´ shadow ¬ª pour l‚Äôoptimiseur; binarisation en avant par seuillage dur; gradients pass√©s via STE born√©.
4) Modules d√©coupl√©s: couches, fonctions utilitaires (pack/unpack, popcount), pertes, m√©triques et kernels s√©par√©s, test√©s unitairement.
5) Determinisme & simplicit√©: API claire, seeds fixables, comportement reproductible.

---

### Alg√®bre binaire (contrat)
- Domaine: {0,1}. Produit binaire ‚âà AND; somme binaire via popcount.
- Dot-product binaire pack√©:
	- Pour {0,1}: sum(x_i AND w_i) = popcount(AND(pack(x), pack(w))) cumul√© sur les mots.
	- Option XNOR/Hamming pour {‚àí1,+1} non utilis√©e ici, sauf exp√©rimentation document√©e.
- Seuil/activation: b(x) = 1 si x ‚â• œÑ, sinon 0. œÑ par d√©faut = 0 ou apprenable par canal.
- Mise √† l‚Äô√©chelle (facultative): y = Œ± ¬∑ s, o√π s est un entier (somme de popcounts); Œ± peut √™tre global ou par canal (float32), appris ou estim√© (style XNOR-Net).

Backward (STE):
- forward: b = (x ‚â• œÑ) ‚àà {0,1}
- backward: ‚àÇL/‚àÇx ‚âà clip(‚àÇL/‚àÇb, ‚àíŒ≥, Œ≥)¬∑ùüô(|x‚àíœÑ| ‚â§ Œî) avec Œî petit (p.ex. 1.0) et Œ≥ pour stabiliser.

---

### API minimale (√† respecter)
- Noms de classes/pr√©fixes: `Nano*`
	- `NanoModule`: base commune (seed, device, dtype, pack_bits=64)
	- `NanoLinear1b(in_features, out_features, bias=False, pack_bits=64, scale="per-channel"|"none")`
	- `NanoConv2d1b(in_ch, out_ch, k, stride=1, pad=0, groups=1, dilation=1, bias=False, pack_bits=64, scale="per-channel"|"none")`
	- `NanoAct1b(threshold=0.0, learnable=True)`
	- `NanoBN1b` (ou √©quivalent: normalisation/centrage binaire l√©ger)
	- `NanoBitpack` utilitaires: `pack`, `unpack`, `popcount_u64`, `and_popcnt(acc, a, b)`
- Entra√Ænement:
	- `binarize(w_real) -> w_bin{0,1}` via seuil 0
	- `shadow weights` en float32, mise √† jour par optimiseur standard; forward utilise `w_bin` pack√©s
	- Pertes usuelles (CE), r√©gulariseurs optionnels: √©quilibre 0/1, p√©nalit√© corr√©lation (Hamming)
- I/O:
	- Sauvegarde binaire: poids pack√©s (uint64), m√©ta (shape, pack_bits, ordre de packing), seuils/√©chelles

Exigences d‚Äôimpl√©mentation:
- Aucun float dans les chemins critiques d‚Äôinf√©rence sauf scalars Œ±/œÑ.
- Bit-packing par canal/sortie; dimension d‚Äôagr√©gation document√©e (N, C, H, W).
- Kernels vectoris√©s si possible; fallback pur Python/Numpy accept√© si clair et test√©.
- Gestion des shapes et padding document√©e (y compris bordures en conv).

---

### Contraintes techniques (obligatoires)
- Poids BIT1 (0/1)
- Activations BIT1 (0/1)
- Calculs adapt√©s binaire (XNOR/XOR/AND/OR + POPCOUNT)
- STE pour la r√©tropropagation (voir contrat ci-dessus)
- Bit-packing syst√©matique (32/64 bits), accumulation en entiers
- √âchelles (Œ±) et seuils (œÑ) au plus en float32, id√©alement par canal

---

### R√©f√©rences d‚Äôentra√Ænement
- BinaryConnect (poids binaires, activations possibles binaires)
- XNOR-Net (facteurs d‚Äô√©chelle; ici adapt√©s √† {0,1})
- Variantes STE (hard-sign/hard-threshold, clip, annealing de œÑ)

R√®gles pratiques:
- Maintenir `w_real` born√©s (p.ex. tanh ou clamp) avant binarisation
- Clipper gradients (p.ex. ¬±1) pour stabilit√©
- Suivre la balance 0/1 par couche; ajouter r√©gularisation si d√©s√©quilibr√©

---

### M√©triques et validation
- Accuracy/Top-k
- BitOPs par inference (approx popcount ops) et MACs √©quivalents
- Popcounts r√©els instrument√©s:
	- Compile-time: `DUDUX_ENABLE_METRICS` (ON par d√©faut) active un compteur global de `popcount_u64`.
	- Runtime: `DUDUX_METRICS=0|1` (ou 7e arg du bench) pour activer/d√©sactiver la mesure sans recompiler.
	- Le bench `dudux_perf` affiche `popcount_calls` pour mono‚Äëm√©moire et routeur.
- Empreinte m√©moire (bits) pour poids + activations
- Marge de Hamming moyenne entre classes
- Latence CPU (et GPU si kernels dispo)

Tests indispensables:
- Correctness pack/unpack sur bords (taille non multiple de pack_bits)
- √âquivalence AND+popcount vs r√©f√©rence na√Øve sur petits tenseurs
- Invariance aux seeds, reproductibilit√©
- Grad-check approximatif autour du seuil (sanity STE)

---

### Optimisations hardware-aware
- CPU: utiliser intrinsics/popcount natif si dispo (p.ex. __builtin_popcountll); vectorisation
- GPU: utiliser bitwise + popc si CUDA, sinon fallback
- M√©moire: data layout contiguous pour parcours s√©quentiel en conv (im2col binaire ou direct)
- M√©moire (routing/index): top‚Äëk streaming O(k) via tas, buffers r√©utilisables, tie‚Äëbreak stable (distance, label) pour reproductibilit√©.

---

### Style & conventions (C++ professionnel)
- Nommage: namespace racine `dudux` (puis sous-espaces `core`, `memory`, `io`‚Ä¶ √† terme).
- Fichiers d‚Äôen-t√™te sous `include/dudux/`. Chaque fichier document√© (Doxygen `@file`, `@brief`).
- Flags: `-O3 -Wall -Wextra -Wpedantic` + `-march=native` optionnel (`DUDUX_ENABLE_NATIVE`).
- Aucune allocation dynamique dans le chemin critique d‚Äôinf√©rence; r√©utiliser buffers.
- Ex√©cutables: `dudux_cli`, `dudux_benchmark`, tests `dudux_unit_tests` (CTest).
- Logs: imprimer balance 0/1, Œ±, œÑ, BitOPs, empreinte m√©moire.

---

### Plan de livraison (ordre sugg√©r√©)
1) Utils bit: pack/unpack, popcount (tests unitaires)
2) NanoLinear1b + NanoAct1b + STE (train/test minimal)
3) Facteurs d‚Äô√©chelle Œ± (none/global/per-channel) et œÑ apprenable
4) NanoConv2d1b (na√Øf) puis version optimis√©e
5) Normalisation binaire l√©g√®re (NanoBN1b) ou folding de stats dans œÑ/Œ±
6) M√©triques, export poids pack√©s, exemples (MNIST/CIFAR petit)

---

### √Ä √©viter
- M√©langer {‚àí1,+1} et {0,1} sans le documenter et adapter l‚Äôalg√®bre
- Introduire des flottants cach√©s en forward (sauf Œ±/œÑ explicitement)
- D√©pendances lourdes sans b√©n√©fice clair

---

En un mot: √©crire du code simple, binaire, mesur√©, et reproductible. Dudux doit rester lisible, testable et pr√™t pour des d√©ploiements tr√®s contraints.

---

### GPU/CUDA (sp√©cifique Dudux)
- Les chemins critiques d'attention disposent d'un backend CUDA optionnel (DUDUX_ENABLE_CUDA):
	- Kernels AND+POPC pour scorer q vs K pack√©s en uint64.
	- Top‚Äëk c√¥t√© device via Thrust (sort_by_key), copie des k meilleurs vers l‚Äôh√¥te.
	- Buffers device persistants: cl√©s (K), scores, indices, candidats, q (√©viter realloc/copys).
- Streams CUDA:
	- API attention accepte un `stream_handle` optionnel pour ex√©cuter sur un flux donn√©.
	- MHA propose une ex√©cution multi‚Äëstream (un flux par t√™te) avec synchro finale pour parall√©liser les t√™tes.
- Gating/candidats:
	- Un routeur l√©ger g√©n√®re un sous‚Äëensemble de candidats par requ√™te (postings index par bit actif).
	- L‚Äôattention ¬´ candidates ¬ª ne score que ces indices, r√©duisant le compute/m√©moire.

Guides 4GB VRAM:
- Pr√©f√©rer NBIT modestes (8‚Äì32k) et VBIT compacts (512‚Äì2048). K petit (4‚Äì16). HEADS 4‚Äì8.
- Activer le gating (CAND 128‚Äì512) et r√©utiliser les buffers device.
- √âviter les allocations par appel; privil√©gier des structures persistantes et les copies asynchrones H2D/D2H.